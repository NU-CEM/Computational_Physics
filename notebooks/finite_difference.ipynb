{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284d7a40",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Finite difference methods\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5baedd",
   "metadata": {},
   "source": [
    "::: {.callout-note icon=false}\n",
    "## Questions\n",
    "* How do I use a finite difference method to calculate derivatives? \n",
    "* What is the Laplacian operator?\n",
    ":::\n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "##  Objectives\n",
    "* Use the finite difference method to calculate the derivative of an unknown function\n",
    "* Express the Laplacian as a differential operator\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2fa1af",
   "metadata": {},
   "source": [
    "### Finite difference methods are a family of techniques used to calculate derivatives\n",
    "\n",
    "Finite-difference methods are a class of numerical techniques for solving differential equations by approximating derivatives with finite differences. They are widely used for solving ordinary and partial differential equations, as they can convert equations that are unsolvable analytically into a set of linear equations that can be solved on a computer.\n",
    "\n",
    "They rely on the idea of discretization: breaking a domain (for example, the space domain) into a finite number of discrete elements. \n",
    "\n",
    "<a title=\"User:Mintz l, Public domain, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Finite_Differences.svg\"><img width=\"256\" alt=\"Finite Differences\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Finite_Differences.svg/512px-Finite_Differences.svg.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144e6c3",
   "metadata": {},
   "source": [
    "### A numerical derivative can be calculated using the forward, backward or central difference methods\n",
    "\n",
    "\n",
    "<a title=\"Kakitc, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Finite_difference_method.svg\"><img width=\"512\" alt=\"Finite difference method\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Finite_difference_method.svg/512px-Finite_difference_method.svg.png\"></a>\n",
    "\n",
    "The standard definition of a derivative is \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} x} = \\lim_{h\\to0}\\frac{f(x+h)-f(x)}{h}.\n",
    "\\end{equation}\n",
    "\n",
    "To calculate the derivative numerically we make $h$ very small and calculate\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} x} \\simeq \\frac{f(x+h)-f(x)}{h}.\n",
    "\\end{equation}\n",
    "\n",
    "This is the <mark>forward difference</mark> because it is measured in the forward direction from $x$.\n",
    "\n",
    "The <mark>backward difference</mark> is measured in the backward direction from $x$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} x} \\simeq \\frac{f(x)-f(x-h)}{h},\n",
    "\\end{equation}\n",
    "\n",
    "and the <mark>central difference</mark> uses both the forwards and backwards directions around $x$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} x} \\simeq \\frac{f(x+\\frac{h}{h2})-f(x-\\frac{h}{2})}{h}.\n",
    "\\end{equation}\n",
    "\n",
    "Let's start with a simple example - let's use the forward difference method to calculate the derivative of $x^2$ at $x=5$ with $h=0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e75205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_squared(x):\n",
    "    return 2*x**2\n",
    "\n",
    "def forward_difference(f_x, x, h):\n",
    "    return (f_x(x+h) - f_x(x)) / h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568b9eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.019999999999527"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_difference(x_squared,5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e58f2",
   "metadata": {},
   "source": [
    "### We need to converge with respect to the step size $h$\n",
    "\n",
    "Our expressions above are approximations as they are only exactly equal to the derivative when the step size $h$ is zero. Whether using forwards, backwards or central differences it is important to converge with respect to a decreasing step size $h$. \n",
    "\n",
    "Note that in the next tutorial we will see that it is also possible to make $h$ too small!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26779f77",
   "metadata": {},
   "source": [
    "As we can see from the example in the image at the top of the page, the central difference is (in general) more accurate than the forward or backward differences.\n",
    "<mark> In fact, the error is order $h$ for the forwards and backwards methods, and order $h^2$ for the central difference. </mark>\n",
    "\n",
    "Let's test this idea using our simple $2x^2$ example that we started above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0faadf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_answer = 20\n",
    "\n",
    "def calculate_x2_error(h):\n",
    "    error = exact_answer - forward_difference(x_squared,5, h)\n",
    "    print (\"error for h={} is {}\".format(h,round(error,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2ea149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for h=0.01 is -0.02\n",
      "error for h=0.005 is -0.01\n",
      "error for h=0.0025 is -0.005\n"
     ]
    }
   ],
   "source": [
    "calculate_x2_error(0.01)\n",
    "calculate_x2_error(0.005)\n",
    "calculate_x2_error(0.0025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2e5ae",
   "metadata": {},
   "source": [
    "We can see that as the step size $h$ is halved, the error halves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29fe736",
   "metadata": {},
   "source": [
    "### Second-order derivatives can be calculated using finite differences\n",
    "\n",
    "The second derivative is a derivative of a derivative, and so we can calculate it be applying the first derivative formulas twice. The resulting expression (after application of central differences) is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d}^2f}{\\mathrm{d} x^2} \\simeq \\frac{f(x+h)-2f(x)+f(x-h)}{h^2}.\n",
    "\\end{equation}\n",
    "\n",
    "Let's test this out using the $2x^2$ example that we started above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e14eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_forward_difference(f_x, x, h):\n",
    "    return (f_x(x+h) - 2*f_x(x) + f_x(x-h)) / (h**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e022ca47-a583-4566-83d0-346abc019443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9999999999906777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_order_forward_difference(x_squared, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a47ab0",
   "metadata": {},
   "source": [
    "The second derivative of $2x^2$ is 4, so the implementation appears correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d6052",
   "metadata": {},
   "source": [
    "### Partial derivatives can be calculated using finite differences\n",
    "\n",
    "The extension to partial derivatives is also relatively straight-forward. At this point we also consider a second dependent variable, $y$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial x} \\simeq \\frac{f(x+\\frac{h}{2},y)-f(x-\\frac{h}{2},y)}{h},\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial f}{\\partial y} \\simeq \\frac{f(x,y+\\frac{h}{2})-f(x,y-\\frac{h}{2})}{h},\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial ^2f}{\\partial x^2} \\simeq \\frac{f(x+h,y)-2f(x,y)+f(x-h,y)}{h^2},\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial ^2f}{\\partial y^2} \\simeq \\frac{f(x,y+h)-2f(x,y)+f(x,y-h)}{h^2}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e431e",
   "metadata": {},
   "source": [
    "Let's consider another example, where we calculate the $x$-component of a force $F$ in a potential energy $U = x^2+y^2$, at $x=5,y=10$. We know that the force and potential energy are calculated as follows:\n",
    "\n",
    "$$F_x = \\frac{\\partial U}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fb30b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_energy(x,y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "def partial_dfdx(f_x, x, y, h):\n",
    "    return (f_x(x+(h/2),y) - f_x(x-(h/2),y)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "017a97f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000000000853"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_dfdx(potential_energy, 5, 10, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd1ea6",
   "metadata": {},
   "source": [
    "Which is close to the analytic answer of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc10c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### The Laplacian operator corresponds to an average rate of change\n",
    "\n",
    "The <mark>Laplacian operator</mark> $\\nabla^2$ is a very important differential operator in physics. We will see it later in the course, when studying partial differential equations. It is used to mathematically describe a variety of physical processes, including diffusion, gravitational potentials, wave propogation and fluid flow.\n",
    "\n",
    "When applied to $f$ and written in full for a two dimensional cartesian coordinate system with dependent variables $x$ and $y$ it takes the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla^2\\phi = \\frac{\\partial^2\\phi}{\\partial x^2} + \\frac{\\partial^2\\phi}{\\partial y^2} + \\frac{\\partial^2\\phi}{\\partial z^2}.\n",
    "\\end{equation}\n",
    "\n",
    "With equivalent expressions for a single dimension or extension to higher dimensions.\n",
    "\n",
    "We can think of the laplacian as encoding an average rate of change. To develop an intuition for how the laplacian can be interpreted physically, we need to understand two related operators - div and curl. We will not explore these operators further in this lesson, but a related video is listed under external resources.\n",
    "\n",
    "### The Laplacian can be calculated using finite differences\n",
    "\n",
    "By adding the two equations for second order partial derivatives (Equations 8 and 9), we find that the Laplacian in two dimensions is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial ^2f}{\\partial x^2} + \\frac{\\partial ^2f}{\\partial y^2} \\simeq \\frac{f(x+h,y)+f(x-h,y)+f(x,y+h)+f(x,y-h)-4f(x,y)}{h^2},\n",
    "\\end{equation}\n",
    "\n",
    "The expression above is known as a <mark>five-point stencil</mark> as it uses five points to calculate the Laplacian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641cb8d",
   "metadata": {},
   "source": [
    "::: {.callout-note icon=false}\n",
    "##  Keypoints\n",
    "\n",
    "- Finite difference methods are a family of techniques used to calculate derivatives\n",
    "- A numerical derivative can be calculated using the forward, backward or central finite difference\n",
    "- We need to converge with respect to the step size $h$\n",
    "- Second-order derivatives, partial derivatives and the Laplacian can also be calculated using finite differences\n",
    "- The Laplacian operator corresponds to an average rate of change\n",
    ":::\n",
    "\n",
    "### Test your understanding\n",
    "\n",
    "::: {.callout-tip icon=false collapse=\"true\" appearance=\"simple\"}\n",
    "## Implementing the Laplacian\n",
    "\n",
    "a) Use a five-point stencil to calculate\n",
    "\n",
    "$$\\nabla^2\\phi = \\frac{\\partial^2\\phi}{\\partial x^2} + \\frac{\\partial^2\\phi}{\\partial y^2} + \\frac{\\partial^2\\phi}{\\partial z^2}$$\n",
    "\n",
    "for $\\phi = 6\\cos(x)+7\\sin(y)$ at $x=\\pi$ and $y=\\pi$, using a step-size of your choice.\n",
    "\n",
    "b) Compare to the exact answer.\n",
    "\n",
    "\n",
    "::: {.callout-tip icon=false collapse=\"true\" appearance=\"simple\"}\n",
    "### Show answer\n",
    "\n",
    "a) \n",
    "\n",
    "~~~python\n",
    "import math\n",
    "\n",
    "def integrand(x,y):\n",
    "    return 6*math.cos(x) + 7*math.sin(y)\n",
    "\n",
    "def laplacian(f_xy, x, y, h):\n",
    "    return (f_xy(x+h,y) + f_xy(x-h,y) + f_xy(x,y+h) + f_xy(x,y-h) - 4*(f_xy(x,y))) / (h**2)    \n",
    "  \n",
    "laplacian(integrand, math.pi, math.pi, 1E-2)\n",
    "~~~\n",
    "\n",
    "~~~output\n",
    "5.999950000159515\n",
    "~~~\n",
    "  \n",
    "b) This is within 1e-5 to the exact answer of 6.\n",
    "\n",
    ":::\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
