{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137b69cc-9be6-4779-b58c-49d05a1c0d77",
   "metadata": {},
   "source": [
    "# Finite difference methods\n",
    "\n",
    "> **Questions**\n",
    ">\n",
    "> -   How do I use a finite difference method to calculate derivatives?\n",
    "> -   What is the Laplacian operator?\n",
    "\n",
    "> **Objectives**\n",
    ">\n",
    "> -   Use the finite difference method to calculate the derivative of an\n",
    ">     unknown function\n",
    "> -   Express the Laplacian as a differential operator\n",
    "\n",
    "### Finite difference methods are a family of techniques used to calculate derivatives\n",
    "\n",
    "Finite-difference methods are a class of numerical techniques for\n",
    "solving differential equations by approximating derivatives with finite\n",
    "differences. They are widely used for solving ordinary and partial\n",
    "differential equations, as they can convert equations that are\n",
    "unsolvable analytically into a set of linear equations that can be\n",
    "solved on a computer.\n",
    "\n",
    "They rely on the idea of discretization: breaking a domain (for example,\n",
    "the space domain) into a finite number of discrete elements.\n",
    "\n",
    "<a title=\"User:Mintz l, Public domain, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Finite_Differences.svg\"><img width=\"256\" alt=\"Finite Differences\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Finite_Differences.svg/512px-Finite_Differences.svg.png\"></a>\n",
    "\n",
    "### A numerical derivative can be calculated using the forward, backward or central difference methods\n",
    "\n",
    "<a title=\"Kakitc, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Finite_difference_method.svg\"><img width=\"512\" alt=\"Finite difference method\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Finite_difference_method.svg/512px-Finite_difference_method.svg.png\"></a>\n",
    "\n",
    "The standard definition of a derivative is\n",
    "\n",
    "To calculate the derivative numerically we make $h$ very small and\n",
    "calculate\n",
    "\n",
    "This is the <mark>forward difference</mark> because it is measured in\n",
    "the forward direction from $x$.\n",
    "\n",
    "The <mark>backward difference</mark> is measured in the backward\n",
    "direction from $x$:\n",
    "\n",
    "and the <mark>central difference</mark> uses both the forwards and\n",
    "backwards directions around $x$:\n",
    "\n",
    "Let’s start with a simple example - let’s use the forward difference\n",
    "method to calculate the derivative of $x^2$ at $x=5$ with $h=0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e75205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_squared(x):\n",
    "    return x**2\n",
    "\n",
    "def forward_difference(f_x, x, h):\n",
    "    return (f_x(x+h) - f_x(x)) / h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568b9eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.009999999999764"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_difference(x_squared,5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166c418",
   "metadata": {},
   "source": [
    "Note that there is a more concise method of defining short functions which is to use a [Lambda](https://www.w3schools.com/python/python_lambda.asp) statement. For example, instead of defining the `x_squared` function we could use a lambda statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3418b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.009999999999764"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = lambda x: x**2\n",
    "forward_difference(x_2, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae061af",
   "metadata": {},
   "source": [
    "Or we can even pass it directly into the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f01d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.009999999999764"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_difference(lambda x: x**2, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065edec6-f7f9-4a10-bab5-851f877c12bb",
   "metadata": {},
   "source": [
    "### We need to converge with respect to the step size $h$\n",
    "\n",
    "Our expressions above are approximations as they are only exactly equal\n",
    "to the derivative when the step size $h$ is zero. Whether using\n",
    "forwards, backwards or central differences it is important to converge\n",
    "with respect to a decreasing step size $h$.\n",
    "\n",
    "Note that in the next tutorial we will see that it is also possible to\n",
    "make $h$ too small!\n",
    "\n",
    "As we can see from the example in the image at the top of the page, the\n",
    "central difference is (in general) more accurate than the forward or\n",
    "backward differences. <mark> In fact, the error is order $h$ for the\n",
    "forwards and backwards methods, and order $h^2$ for the central\n",
    "difference. </mark>\n",
    "\n",
    "Let’s test this idea using our simple $x^2$ example that we started\n",
    "above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0faadf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_answer = 20\n",
    "\n",
    "def calculate_x2_error(h):\n",
    "    error = exact_answer - forward_difference(x_squared,5, h)\n",
    "    print (\"error for h={} is {}\".format(h,round(error,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2ea149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for h=0.01 is 9.99\n",
      "error for h=0.005 is 9.995\n",
      "error for h=0.0025 is 9.9975\n"
     ]
    }
   ],
   "source": [
    "calculate_x2_error(0.01)\n",
    "calculate_x2_error(0.005)\n",
    "calculate_x2_error(0.0025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f2702-31b7-45dc-a07a-74aae16cc8d4",
   "metadata": {},
   "source": [
    "We can see that as the step size $h$ is halved, the error halves.\n",
    "\n",
    "### Second-order derivatives can be calculated using finite differences\n",
    "\n",
    "The second derivative is a derivative of a derivative, and so we can\n",
    "calculate it be applying the first derivative formulas twice. The\n",
    "resulting expression (after application of central differences) is:\n",
    "\n",
    "Let’s test this out using the $x^2$ example that we started above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e14eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_forward_difference(f_x, x, h):\n",
    "    return (f_x(x+h) - 2*f_x(x) + f_x(x-h)) / (h**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e022ca47-a583-4566-83d0-346abc019443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999999999953388"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_order_forward_difference(x_squared, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894ac54-286c-4d1b-be5d-a0e0886ec13f",
   "metadata": {},
   "source": [
    "The second derivative of $x^2$ is 2, so the implementation appears\n",
    "correct.\n",
    "\n",
    "### Partial derivatives can be calculated using finite differences\n",
    "\n",
    "The extension to partial derivatives is also relatively\n",
    "straight-forward. At this point we also consider a second dependent\n",
    "variable, $y$.\n",
    "\n",
    "Let’s consider another example, where we calculate the $x$-component of\n",
    "a force $F$ in a potential energy $U = x^2+y^2$, at $x=5,y=10$. We know\n",
    "that the force and potential energy are calculated as follows:\n",
    "\n",
    "$$F_x = \\frac{\\partial U}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb30b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_energy(x,y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "def partial_dfdx(f_xy, x, y, h):\n",
    "    return (f_xy(x+(h/2),y) - f_xy(x-(h/2),y)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017a97f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000000000853"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_dfdx(potential_energy, 5, 10, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7447076-69c0-4d22-8d55-934de87d8fc3",
   "metadata": {},
   "source": [
    "Which is close to the analytic answer of 10.\n",
    "\n",
    "### The Laplacian operator corresponds to an average rate of change\n",
    "\n",
    "The <mark>Laplacian operator</mark> $\\nabla^2$ is a very important\n",
    "differential operator in physics. We will see it later in the course,\n",
    "when studying partial differential equations. It is used to\n",
    "mathematically describe a variety of physical processes, including\n",
    "diffusion, gravitational potentials, wave propogation and fluid flow.\n",
    "\n",
    "When applied to $f$ and written in full for a two dimensional cartesian\n",
    "coordinate system with dependent variables $x$ and $y$ it takes the\n",
    "following form:\n",
    "\n",
    "With equivalent expressions for a single dimension or extension to\n",
    "higher dimensions.\n",
    "\n",
    "We can think of the laplacian as encoding an average rate of change. To\n",
    "develop an intuition for how the laplacian can be interpreted\n",
    "physically, we need to understand two related operators - div and curl.\n",
    "We will not explore these operators further in this lesson, but a\n",
    "related video is listed under external resources.\n",
    "\n",
    "### The Laplacian can be calculated using finite differences\n",
    "\n",
    "By adding the two equations for second order partial derivatives\n",
    "(Equations 8 and 9), we find that the Laplacian in two dimensions is:\n",
    "\n",
    "The expression above is known as a <mark>five-point stencil</mark> as it\n",
    "uses five points to calculate the Laplacian.\n",
    "\n",
    "> **Keypoints**\n",
    ">\n",
    "> -   Finite difference methods are a family of techniques used to\n",
    ">     calculate derivatives\n",
    "> -   A numerical derivative can be calculated using the forward,\n",
    ">     backward or central finite difference\n",
    "> -   We need to converge with respect to the step size $h$\n",
    "> -   Second-order derivatives, partial derivatives and the Laplacian\n",
    ">     can also be calculated using finite differences\n",
    "> -   The Laplacian operator corresponds to an average rate of change\n",
    "\n",
    "### Test your understanding\n",
    "\n",
    "> **Implementing the Laplacian**\n",
    ">\n",
    "> 1.  Use a five-point stencil to calculate\n",
    ">\n",
    "> $$\\nabla^2\\phi = \\frac{\\partial^2\\phi}{\\partial x^2} + \\frac{\\partial^2\\phi}{\\partial y^2} + \\frac{\\partial^2\\phi}{\\partial z^2}$$\n",
    ">\n",
    "> for $\\phi = 6\\cos(x)+7\\sin(y)$ at $x=\\pi$ and $y=\\pi$, using a\n",
    "> step-size of your choice.\n",
    ">\n",
    "> 1.  Compare to the exact answer.\n",
    ">\n",
    "> > **Show answer**\n",
    "> >\n",
    "> > 1.  \n",
    "> >\n",
    "> > ``` python\n",
    "> > import math\n",
    "> >\n",
    "> > def integrand(x,y):\n",
    "> >     return 6*math.cos(x) + 7*math.sin(y)\n",
    "> >\n",
    "> > def laplacian(f_xy, x, y, h):\n",
    "> >     return (f_xy(x+h,y) + f_xy(x-h,y) + f_xy(x,y+h) + f_xy(x,y-h) - 4*(f_xy(x,y))) / (h**2)    \n",
    "> >   \n",
    "> > laplacian(integrand, math.pi, math.pi, 1E-2)\n",
    "> > ```\n",
    "> >\n",
    "> > ``` output\n",
    "> > 5.999950000159515\n",
    "> > ```\n",
    "> >\n",
    "> > 1.  This is within 1e-5 to the exact answer of 6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
